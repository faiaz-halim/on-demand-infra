# MCP Server - Product Requirements Document

<PRD>

# Technical Architecture

## System Components
1.  **MCP Server Core**
    *   Handles primary user interaction via an OpenAI compatible API.
    *   Orchestrates workflows for different deployment modes (local, cloud-local, cloud-hosted).
    *   Manages GitHub repository interactions (cloning, analysis of README.md, Dockerfile checks).
    *   Integrates with AI services for language understanding and code generation assistance.
    *   Generates Terraform modules specifically for AWS cloud resources.
    *   Generates Kubernetes manifests for application deployment.
    *   Builds Docker images from application source code.
    *   Communicates with other MCP servers (e.g., Context7) or searches the web for documentation and best practices.

2.  **AI Integration Layer**
    *   Integrates with Azure OpenAI API for chat processing, understanding user intent, and assisting in code generation.
    *   Facilitates tool calls to external services (Context7 MCP, web search) to gather contextual information, documentation, and best practices for Terraform and AWS.

3.  **API Layer**
    *   Exposes an OpenAI API compatible endpoint (e.g., `/v1/chat/completions`) for receiving user prompts and streaming responses.
    *   Handles input validation for parameters like GitHub repository URL, deployment mode, and AWS credentials.

4.  **Deployment Mode Handler**
    *   Manages the distinct logic for `local`, `cloud-local`, and `cloud-hosted` deployment modes.
    *   Prompts user for AWS credentials and specific configurations (e.g., namespace, instance size) based on the selected mode.

5.  **Terraform Module Engine**
    *   Responsible for generating Terraform HCL code for AWS resources.
    *   Supports provisioning of EC2 instances, EKS clusters, ECR repositories, Security Groups, Load Balancers (ALB/NLB), Route53 records, and ACM certificates.
    *   Follows best practices for security and scalability in generated Terraform code.

6.  **Kubernetes Manifest Engine**
    *   Generates Kubernetes YAML manifests for application deployment.
    *   Supports Deployments, Services (NodePort, LoadBalancer), Secrets, Namespaces, and Ingress (Nginx).
    *   Adapts manifests for different environments (Kind, EKS).

7.  **Local Deployment Environment (Kind)**
    *   Utilizes a local Kind Kubernetes cluster for `local` mode deployments.
    *   Loads locally built Docker images into the Kind cluster.
    *   Uses Calico CNI (template to be provided).
    *   Manages application lifecycle within Kind (deployment, scaling, updates, decommissioning).

8.  **Cloud-Local Deployment Environment (EC2+Kind)**
    *   Provisions an AWS EC2 instance for `cloud-local` mode.
    *   Installs Docker, Kind, and other prerequisites on the EC2 instance using Terraform.
    *   Builds Docker images and deploys applications to Kind on the EC2 instance.
    *   Manages application lifecycle and underlying EC2 infrastructure via Terraform.

9.  **Cloud-Hosted Deployment Environment (EKS)**
    *   Provisions an AWS EKS cluster with managed nodes for `cloud-hosted` mode.
    *   Builds Docker images using Docker-in-Docker and pushes them to AWS ECR.
    *   Deploys applications to EKS, exposing them via Nginx Ingress and AWS Load Balancers.
    *   Manages application lifecycle and EKS infrastructure via Terraform.

## Data Models

### API Request Model
```json
{
  "prompt": "User's chat message",
  "github_repository_url": "https://github.com/user/repo.git",
  "deployment_mode": "local|cloud-local|cloud-hosted",
  "aws_credentials": { // Optional, required for cloud-local and cloud-hosted
    "aws_access_key_id": "string",
    "aws_secret_access_key": "string",
    "aws_region": "string"
  },
  "instance_size": "string", // Optional, for cloud-local EC2
  "application_environment_variables": { // Optional
    "VAR_NAME": "value"
  },
  "namespace": "string" // Optional, for local mode if Kind cluster exists
}
```

### GitHub Repo Analysis Model
```json
{
  "repository_url": "string",
  "has_readme": true,
  "readme_content": "string", // Extracted build/run instructions
  "has_dockerfile": true,
  "dockerfile_content": "string",
  "identified_build_command": "string", // Or user provided
  "identified_run_command": "string" // Or user provided
}
```

### Terraform Configuration Model (Conceptual)
*   Internal representation of Terraform resources, variables, and outputs for various AWS services (EC2, VPC, S3, EKS, ECR, ELB, Route53, ACM, IAM).

### Kubernetes Manifest Model (Conceptual)
*   Internal representation of Kubernetes objects (Deployment, Service, Ingress, Secret, Namespace) tailored for Kind or EKS.

### Tool Call Request/Response Model
```json
{
  "tool_name": "context7_search | web_search",
  "query": "terraform aws eks security best practices",
  "context": "string" // Optional additional context
}
```
```json
{
  "tool_name": "context7_search | web_search",
  "results": [
    {
      "source": "url or document_id",
      "content_snippet": "string"
    }
  ]
}
```

## APIs and Integrations
1.  **Azure OpenAI API**
    *   Authentication via API key (environment variable).
    *   Used for natural language understanding, intent recognition, and assisting in code generation.
2.  **GitHub API / Git CLI**
    *   Used for cloning public repositories specified by the user.
    *   No authentication required for public repositories.
3.  **Context7 MCP / Web Search API (Generic)**
    *   Interface for querying external knowledge sources for documentation and best practices.
    *   Specific API details TBD based on chosen provider(s).
4.  **AWS SDK / Terraform AWS Provider**
    *   Used implicitly by Terraform to interact with AWS services for provisioning and management.
    *   Requires AWS credentials provided by the user for `cloud-local` and `cloud-hosted` modes.
5.  **Docker CLI / Engine API**
    *   Used for building Docker images from application source code.
    *   Used for Docker-in-Docker builds in `cloud-hosted` mode.
    *   MCP server's host environment must have Docker installed.
6.  **Kubernetes API (Kind / EKS)**
    *   Used for deploying and managing applications within Kind clusters or EKS clusters.
    *   Interaction managed via `kubectl` commands or Kubernetes client libraries, driven by generated manifests.

## Infrastructure Requirements
1.  **MCP Server Host Environment**
    *   Docker and Docker Compose must be pre-installed.
    *   Sufficient resources (CPU, RAM, Disk) to run the MCP server, build Docker images, and potentially a local Kind cluster.
2.  **Local Mode Target Environment**
    *   Kind Kubernetes installed (or MCP can install it if a module is provided).
    *   Calico CNI (template to be provided by user/system).
3.  **Cloud-Local Mode Target Environment (AWS)**
    *   AWS EC2 instance (minimum 4 CPU, 8GB RAM, user-configurable).
    *   EC2 instance will have Docker, Kind, and other prerequisites installed by Terraform.
4.  **Cloud-Hosted Mode Target Environment (AWS)**
    *   AWS EKS cluster (managed nodes).
    *   AWS ECR for storing Docker images.
    *   AWS Load Balancer (NLB) for Nginx Ingress.
    *   AWS Route53 for DNS management (a hosted zone must be available).
    *   AWS Certificate Manager (ACM) for SSL/TLS certificates.

# Development Roadmap

## Phase 1: Core Engine & Local Deployment Mode
1.  **API Implementation & Basic Chat**
    *   Implement OpenAI compatible API endpoint (`/v1/chat/completions`).
    *   Integrate with Azure OpenAI for initial prompt processing and basic responses.
2.  **GitHub Integration**
    *   Implement cloning of public GitHub repositories.
    *   Analyze README.md for build/run instructions (simple parsing).
    *   Check for Dockerfile presence; prompt user if missing or instructions unclear.
3.  **Dockerfile Analysis & Local Image Building**
    *   Implement basic Dockerfile best practice checks (e.g., avoid root user, use specific base images).
    *   Build Docker images locally using the host's Docker daemon.
4.  **Kind Cluster Interaction & Application Deployment (Local Mode)**
    *   Generate Terraform for Kind cluster setup (if not already running, using provided template).
    *   Generate Kubernetes manifests (Deployment, Service with NodePort, Secrets from user input).
    *   Support for creating new namespaces in existing Kind clusters.
    *   Load local Docker images into Kind.
    *   Implement commands/logic for application deployment, redeployment, scaling (within Kind), and decommissioning.
5.  **Initial Terraform/Kubernetes Generation Logic**
    *   Develop foundational logic for generating simple Terraform (Kind config) and Kubernetes (Deployment, Service) configurations.

## Phase 2: Cloud-Local Deployment Mode & Contextualization
1.  **Cloud-Local Mode Orchestration**
    *   Implement logic to handle `cloud-local` mode selection.
    *   Securely handle AWS credential input from the user.
2.  **Terraform for EC2 & Prerequisites**
    *   Generate Terraform modules to provision an EC2 instance (with specified size), including Security Groups and Public IP.
    *   Use Terraform (e.g., user-data scripts or remote-exec provisioners) to install Docker, Kind, and any other necessary tools on the EC2 instance.
3.  **Remote Application Build & Deployment to Kind on EC2**
    *   Automate cloning of the app repository onto the EC2 instance.
    *   Build Docker images on the EC2 instance.
    *   Deploy the application to the Kind cluster running on the EC2 instance.
    *   Expose application via EC2's public IP or a simple Load Balancer configured by Terraform.
4.  **Tool Call Integration (Contextualization)**
    *   Implement framework for tool calls (e.g., to Context7 MCP or web search).
    *   Develop initial prompts for fetching Terraform documentation and AWS best practices related to user queries or generated modules.
5.  **Lifecycle Management (Cloud-Local)**
    *   Handle redeployment, scaling (within Kind on EC2).
    *   Implement decommissioning (Terraform destroy for the entire EC2 setup).

## Phase 3: Cloud-Hosted (EKS) Deployment Mode
1.  **Cloud-Hosted Mode Orchestration**
    *   Implement logic for `cloud-hosted` mode.
2.  **Terraform for EKS Core Infrastructure**
    *   Generate Terraform modules for AWS EKS cluster (managed node groups).
    *   Generate Terraform for AWS ECR repository creation.
3.  **Docker-in-Docker Build & ECR Push**
    *   Implement Docker-in-Docker build process for application images.
    *   Push built images to the AWS ECR repository.
4.  **EKS Deployment & Nginx Ingress Setup**
    *   Generate Kubernetes manifests for deploying applications to EKS (referencing images in ECR).
    *   Generate Terraform/Kubernetes manifests to install Nginx Ingress Controller in EKS.
    *   Configure Ingress resources to expose applications.
5.  **Networking, DNS, and SSL/TLS (Cloud-Hosted)**
    *   Generate Terraform for AWS Network Load Balancer (NLB) for Nginx Ingress.
    *   Generate Terraform for Route53 subdomain creation (assuming a parent hosted zone is available).
    *   Generate Terraform for AWS Certificate Manager (ACM) to create and associate SSL/TLS certificates with the NLB.
    *   Manage Security Groups for EKS cluster access and NLB.
6.  **User Access & Lifecycle Management (Cloud-Hosted)**
    *   Provide the user with the final HTTPS URL for the deployed application.
    *   Handle redeployment, scaling, and decommissioning (Terraform destroy for EKS and related resources).

## Phase 4: Polish, Testing & External Integration
1.  **Advanced API Compatibility & Frontend Testing**
    *   Thoroughly test OpenAI API compatibility with popular frontends like Open WebUI.
    *   Refine streaming responses and error handling.
2.  **Comprehensive Security Review**
    *   Review generated Terraform and Kubernetes configurations for security best practices.
    *   Ensure secure handling of AWS credentials and other secrets.
3.  **Robust Error Handling & User Feedback**
    *   Implement detailed error messages and guidance for users.
4.  **Documentation**
    *   Create user documentation for API usage, deployment modes, and prerequisites.
5.  **Extensive Testing**
    *   End-to-end testing for all deployment modes with various application types.

# Logical Dependency Chain

## Foundation Layer
1.  **API Implementation & Basic Chat (Phase 1)**
    *   Core user interaction point.
2.  **GitHub Integration (Phase 1)**
    *   Essential for accessing application code.
3.  **Dockerfile Analysis & Local Image Building (Phase 1)**
    *   Prerequisite for any deployment.

## Local Deployment Layer
4.  **Kind Cluster Interaction & Application Deployment (Local Mode - Phase 1)**
    *   Establishes the first operational deployment mode.
    *   Develops foundational Terraform/Kubernetes generation logic.

## Cloud & Contextualization Layer
5.  **Cloud-Local Mode Orchestration & EC2 Provisioning (Phase 2)**
    *   Extends deployment capabilities to AWS.
    *   Requires AWS credential handling.
6.  **Tool Call Integration (Phase 2)**
    *   Enhances code generation with external knowledge. Can be developed in parallel once core AI integration is ready.

## Advanced Cloud Layer
7.  **Cloud-Hosted Mode Orchestration & EKS Provisioning (Phase 3)**
    *   Builds upon cloud experience from Phase 2.
    *   Introduces more complex AWS services (EKS, ECR, Route53, ACM).

## Finalization Layer
8.  **Polish, Testing & External Integration (Phase 4)**
    *   Ensures robustness, security, and usability across all features.

# Risks and Mitigations

## Technical Challenges
1.  **API Reliability (Azure OpenAI, GitHub, AWS, Context7/Web Search)**
    *   **Risk**: External API downtime, rate limiting, or breaking changes.
    *   **Mitigation**: Implement robust error handling, retries with exponential backoff. Cache non-volatile data where appropriate. Clearly communicate service dependencies.
2.  **Complexity of IaC Generation (Terraform & Kubernetes)**
    *   **Risk**: Generating incorrect, insecure, or non-optimal IaC for diverse applications and AWS services.
    *   **Mitigation**: Start with well-defined templates for common patterns. Use AI assistance for adapting templates rather than full generation initially. Leverage official AWS/Terraform/Kubernetes documentation and best practices. Implement validation steps for generated code. Allow users to review/modify generated code before application.
3.  **Dockerfile Variability and Build Failures**
    *   **Risk**: User-provided Dockerfiles may be misconfigured, use unsupported features, or fail during builds.
    *   **Mitigation**: Implement pre-build checks and linting for Dockerfiles. Provide clear error reporting from Docker build process. Document supported Dockerfile practices.
4.  **Accuracy of Contextual Information from Tool Calls**
    *   **Risk**: Tool calls (Context7/Web Search) might return irrelevant or outdated information.
    *   **Mitigation**: Refine prompts for tool calls. Allow users to provide their own context or override suggestions. Potentially use multiple sources and rank results.
5.  **Security of Generated IaC and Credentials Handling**
    *   **Risk**: Generated Terraform/Kubernetes might have security vulnerabilities. Mishandling of user AWS credentials.
    *   **Mitigation**: Adhere to principle of least privilege for generated IAM roles/policies. Sanitize inputs. Securely manage and transmit credentials (e.g., prompt when needed, avoid storing long-term if possible). Encourage review of generated code by users. Regularly update knowledge base on security best practices.

## MVP Definition
1.  **Feature Prioritization for MVP**
    *   **Risk**: Including too many features or modes in the MVP could delay initial release and feedback.
    *   **Mitigation**: Define MVP as:
        *   Core API endpoint (OpenAI compatible).
        *   GitHub repo cloning and basic analysis.
        *   Local Docker image building.
        *   `local` deployment mode (deployment to a pre-existing or template-based Kind cluster).
        *   Basic Terraform/Kubernetes generation for the `local` mode.
2.  **Phased Rollout**
    *   **Mitigation**: Follow the defined development roadmap, releasing features incrementally by phase, allowing for user feedback at each stage.

## Scope Creep
1.  **Platform/Tool Expansion Requests**
    *   **Risk**: Users might request support for other cloud providers (Azure, GCP), other IaC tools (Pulumi, CloudFormation), or non-Dockerized applications.
    *   **Mitigation**: Clearly state the project's focus on AWS with Terraform for Dockerized applications in all documentation. Defer out-of-scope requests to future considerations. Build a modular architecture that *could* support extensions later, but don't implement them initially.

## User Expectations
1.  **"Magic" IaC Generation**
    *   **Risk**: Users might expect the MCP server to perfectly generate complex, production-ready IaC for any application with minimal input.
    *   **Mitigation**: Clearly communicate that the MCP server is an assistant/accelerator. Emphasize that generated code should be reviewed. Provide transparency into the generation process (e.g., what documentation sources were consulted). Start with simpler, common use cases.
2.  **Cost Implications of Cloud Modes**
    *   **Risk**: Users might not be fully aware of the AWS costs incurred by `cloud-local` and `cloud-hosted` modes.
    *   **Mitigation**: Provide clear warnings about potential AWS costs before provisioning resources. Allow users to specify smaller/cheaper instance types where feasible (e.g., for `cloud-local` EC2). Make decommissioning (Terraform destroy) straightforward.

## Resource Constraints
1.  **Development Capacity**
    *   **Risk**: The project is ambitious and may require significant development effort.
    *   **Mitigation**: Phased implementation. Focus on core, high-value features first. Leverage existing open-source libraries and tools where possible.
2.  **AI API Costs (Azure OpenAI)**
    *   **Risk**: Extensive use of Azure OpenAI API could lead to high operational costs.
    *   **Mitigation**: Optimize prompts for token efficiency. Implement caching for repetitive queries if applicable. Allow users to configure or be aware of their own API key usage if the model supports it.
3.  **Testing Environment Costs (AWS)**
    *   **Risk**: Testing `cloud-local` and `cloud-hosted` modes will incur AWS costs.
    *   **Mitigation**: Automate infrastructure teardown after tests. Use smallest possible instance/cluster sizes for testing. Utilize AWS free tier resources where applicable.

# Appendix

## AI Prompt Engineering Specifications

### Initial User Chat Prompt Processing
*   **Goal**: Understand user intent, extract key parameters (GitHub URL, desired mode, specific requests).
*   **Structure Example**:
    ```
    You are an AI assistant helping deploy applications to AWS using Terraform and Kubernetes.
    User prompt: {user_input_text}
    Extract the following if present:
    - GitHub repository URL: (e.g., https://github.com/user/repo.git)
    - Deployment mode: (local, cloud-local, cloud-hosted)
    - Specific instructions for build/run: (text)
    - Application environment variables: (key-value pairs)
    - AWS EC2 instance size preference (for cloud-local): (text)
    - Namespace (for local mode): (text)
    If GitHub URL is missing, ask for it.
    If deployment mode is missing, ask for it or suggest a default.
    ```

### GitHub Repo Analysis Query Structure (Internal)
*   **Goal**: Determine build system, language, Dockerfile presence, and extract build/run commands from README.
*   **Structure Example (Conceptual for LLM thought process)**:
    ```
    Analyze the content of this README.md: {readme_content}
    And this Dockerfile: {dockerfile_content}
    Identify:
    1. Commands to build the application.
    2. Commands to run the application.
    3. Main programming language/framework.
    4. Any specific prerequisites mentioned.
    ```

### Dockerfile Check Prompt Structure (Internal)
*   **Goal**: Identify potential issues or areas for improvement in a Dockerfile.
*   **Structure Example**:
    ```
    Review this Dockerfile for best practices and potential misconfigurations:
    {dockerfile_content}
    Check for:
    - Use of non-root user.
    - Specificity of base image versions.
    - Multi-stage builds for smaller final images.
    - Efficient layer caching (order of commands).
    - Unnecessary exposure of ports.
    - Hardcoded secrets.
    Provide suggestions for improvement.
    ```

### Terraform/Kubernetes Generation Assistance Prompt (Internal - High-Level)
*   **Goal**: Guide the LLM to assist in generating specific IaC configurations based on context.
*   **Structure Example**:
    ```
    Given the application requirements (e.g., {app_type}, needs database {db_type}, expects traffic on port {port_num}) and the target deployment mode ({mode_details}),
    Suggest a Terraform configuration snippet for provisioning {specific_aws_resource like 'EKS node group with t3.medium instances'}
    OR
    Suggest a Kubernetes Deployment manifest for an application with {x} replicas, image {image_name}, exposing port {port_num}, and requiring environment variables {env_vars}.
    Ensure the suggestion aligns with security best practices for {aws_resource/kubernetes_object}.
    ```

### Tool Call Prompt for Documentation Search (Context7/Web)
*   **Goal**: Fetch relevant, up-to-date documentation or best practices.
*   **Structure Example**:
    ```
    Search for information on: "{specific_query_from_mcp_or_user}"
    Focus on:
    - Official AWS documentation
    - Terraform Registry documentation
    - Reputable community blogs and articles on best practices
    - Security considerations for {technology/service}
    Return concise summaries and source URLs.
    Example query: "terraform aws eks secure node group configuration"
    ```

## File System Specification (Illustrative)

```
/mcp_server_root/
├── templates/
│   ├── kind/
│   │   ├── kind-config.yaml.tpl  // Kind cluster config template
│   │   └── calico.yaml           // Calico CNI manifest
│   ├── terraform/
│   │   └── aws/
│   │       ├── ec2_instance_base.tf.tpl
│   │       └── eks_cluster_base.tf.tpl
│   └── kubernetes/
│       ├── deployment.yaml.tpl
│       └── service_nodeport.yaml.tpl
├── workspace/
│   └── <session_or_request_id>/
│       ├── <cloned_github_repo_name>/ // Application source code
│       │   └── ...
│       ├── generated_terraform/
│       │   └── main.tf
│       ├── generated_kubernetes/
│       │   ├── deployment.yaml
│       │   └── service.yaml
│       └── build_logs/
│           └── docker_build.log
├── .env                   // For MCP server configuration (e.g., Azure API Key)
└── mcp_server.py          // Main application
```

## API Specification (OpenAI Compatible)

### Endpoint: `/v1/chat/completions`
*   **Method**: `POST`
*   **Request Body (JSON)**:
    *   `model`: (string, optional) Can be used to specify internal routing or capabilities.
    *   `messages`: (array of objects) Standard OpenAI message format.
        *   `role`: "system" | "user" | "assistant"
        *   `content`: (string) Chat message content.
    *   `stream`: (boolean, optional, default: false) Whether to stream responses.
    *   **Custom Parameters (passed within a `data` object or similar, TBD):**
        *   `github_repository_url`: (string, required if not previously provided)
        *   `deployment_mode`: (string, "local" | "cloud-local" | "cloud-hosted", required if not previously provided)
        *   `aws_credentials`: (object, optional)
            *   `aws_access_key_id`: string
            *   `aws_secret_access_key`: string
            *   `aws_region`: string
        *   `instance_size`: (string, optional for `cloud-local`) e.g., "t3.medium"
        *   `application_environment_variables`: (object, optional) Key-value pairs.
        *   `namespace`: (string, optional for `local` mode)
*   **Response Body (JSON or Server-Sent Events if streaming)**:
    *   Standard OpenAI compatible response structure for chat completions.
    *   Content will include generated text, status updates, URLs to deployed applications, or error messages.

## Deployment Mode Specifications

### 1. Local Mode
*   **Goal**: Deploy application to a local Kind Kubernetes cluster.
*   **Workflow**:
    1.  User selects `local` mode, provides GitHub URL.
    2.  MCP clones repo, analyzes Dockerfile/README.
    3.  MCP builds Docker image locally.
    4.  MCP checks for existing Kind cluster or creates one using a template (e.g., `templates/kind/kind-config.yaml.tpl`). Installs Calico CNI from `templates/kind/calico.yaml`.
    5.  User may be asked for a namespace if cluster exists.
    6.  MCP generates Kubernetes manifests (Deployment, Service with NodePort, Secrets for env vars).
    7.  MCP loads Docker image into Kind nodes.
    8.  MCP applies manifests to deploy the application.
    9.  MCP provides user with NodePort URL (e.g., `http://localhost:<nodeport>`).
    10. Handles redeployment, scaling (kubectl scale), decommission (kubectl delete namespace/resources).

### 2. Cloud-Local Mode
*   **Goal**: Deploy application to a Kind cluster running on a dedicated AWS EC2 instance.
*   **Workflow**:
    1.  User selects `cloud-local` mode, provides GitHub URL, AWS credentials, optionally EC2 instance size.
    2.  MCP generates Terraform to:
        *   Provision EC2 instance (e.g., using `templates/terraform/aws/ec2_instance_base.tf.tpl`).
        *   Setup Security Group (allow SSH, app ports).
        *   Install Docker, Kind, Calico, and any other prerequisites on EC2 via user-data or provisioners.
    3.  MCP applies Terraform.
    4.  MCP (or script on EC2) clones app repo, builds Docker image on EC2.
    5.  MCP (or script on EC2) loads image into Kind on EC2, deploys app using generated K8s manifests.
    6.  Application exposed via EC2 Public IP and NodePort, or simple AWS Load Balancer configured by Terraform.
    7.  MCP provides user with public URL.
    8.  Handles redeployment, scaling (within Kind), decommission (Terraform destroy for EC2 and related resources).

### 3. Cloud-Hosted Mode
*   **Goal**: Deploy application to AWS EKS, exposed via NLB and Route53, with SSL.
*   **Workflow**:
    1.  User selects `cloud-hosted` mode, provides GitHub URL, AWS credentials. Assumes a Route53 hosted zone is available.
    2.  MCP generates Terraform to:
        *   Create ECR repository.
        *   Create EKS cluster with managed node groups (e.g., using `templates/terraform/aws/eks_cluster_base.tf.tpl`).
        *   Setup VPC, subnets, IAM roles for EKS.
    3.  MCP applies initial Terraform.
    4.  MCP performs Docker-in-Docker build of application, pushes image to ECR.
    5.  MCP generates Kubernetes manifests (Deployment using ECR image, Service type LoadBalancer or ClusterIP).
    6.  MCP generates Terraform/Kubernetes manifests to install Nginx Ingress controller in EKS.
    7.  MCP configures Ingress resource for the application.
    8.  MCP generates Terraform to:
        *   Provision AWS Network Load Balancer (NLB) for Nginx Ingress.
        *   Create Route53 subdomain record pointing to NLB.
        *   Create ACM certificate for the subdomain and attach to NLB listener.
    9.  MCP applies remaining Terraform and Kubernetes manifests.
    10. MCP provides user with HTTPS URL of the application.
    11. Handles redeployment, scaling (EKS autoscaling/manual), decommission (Terraform destroy).

</PRD>
